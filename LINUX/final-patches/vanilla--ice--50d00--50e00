diff --git a/ice/ice_base.c b/ice/ice_base.c
index 5985a7e5ca8a..7db16b634a4e 100644
--- a/ice/ice_base.c
+++ b/ice/ice_base.c
@@ -5,6 +5,10 @@
 #include "ice_base.h"
 #include "ice_lib.h"
 #include "ice_dcb_lib.h"
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#define NETMAP_ICE_BASE
+#include <ice_netmap_linux.h>
+#endif
 
 /**
  * __ice_vsi_get_qs_contig - Assign a contiguous chunk of queues to VSI
@@ -424,6 +428,10 @@ int ice_setup_rx_ctx(struct ice_ring *ring)
 	/* Rx queue threshold in units of 64 */
 	rlan_ctx.lrxqthresh = 1;
 
+#ifdef DEV_NETMAP
+	ice_netmap_preconfigure_rx_ring(ring, &rlan_ctx);
+#endif /* DEV_NETMAP */
+
 	/* Enable Flexible Descriptors in the queue context which
 	 * allows this driver to select a specific receive descriptor format
 	 * increasing context priority to pick up profile ID; default is 0x01;
@@ -476,6 +484,11 @@ int ice_setup_rx_ctx(struct ice_ring *ring)
 		return 0;
 	}
 
+#ifdef DEV_NETMAP
+	if (ice_netmap_configure_rx_ring(ring))
+		return 0;
+#endif /* DEV_NETMAP */
+
 	ice_alloc_rx_bufs(ring, num_bufs);
 
 	return 0;
@@ -728,6 +741,10 @@ ice_vsi_cfg_txq(struct ice_vsi *vsi, struct ice_ring *ring,
 	if (pf_q == le16_to_cpu(txq->txq_id))
 		ring->txq_teid = le32_to_cpu(txq->q_teid);
 
+#ifdef DEV_NETMAP
+	ice_netmap_configure_tx_ring(ring);
+#endif /* DEV_NETMAP */
+
 	return 0;
 }
 
diff --git a/ice/ice_main.c b/ice/ice_main.c
index 0eb2307325d3..41b3bb90bd8b 100644
--- a/ice/ice_main.c
+++ b/ice/ice_main.c
@@ -35,6 +35,11 @@ MODULE_PARM_DESC(debug, "netif level (0=none,...,16=all), hw debug_mask (0x8XXXX
 MODULE_PARM_DESC(debug, "netif level (0=none,...,16=all)");
 #endif /* !CONFIG_DYNAMIC_DEBUG */
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#define NETMAP_ICE_LIB
+#include <ice_netmap_linux.h>
+#endif
+
 static struct workqueue_struct *ice_wq;
 static const struct net_device_ops ice_netdev_safe_mode_ops;
 static const struct net_device_ops ice_netdev_ops;
@@ -4282,6 +4287,10 @@ ice_probe(struct pci_dev *pdev, const struct pci_device_id __always_unused *ent)
 
 	/* ready to go, so clear down state bit */
 	clear_bit(ICE_DOWN, pf->state);
+
+#ifdef DEV_NETMAP
+	ice_netmap_attach(pf);
+#endif
 	return 0;
 
 err_netdev_reg:
@@ -4382,6 +4391,9 @@ static void ice_remove(struct pci_dev *pdev)
 	if (!pf)
 		return;
 
+#ifdef DEV_NETMAP
+	ice_netmap_detach(pf);
+#endif /* DEV_NETMAP */
 	for (i = 0; i < ICE_MAX_RESET_WAIT; i++) {
 		if (!ice_is_reset_in_progress(pf->state))
 			break;
diff --git a/ice/ice_txrx.c b/ice/ice_txrx.c
index 04748aa4c7c8..b02a895af69e 100644
--- a/ice/ice_txrx.c
+++ b/ice/ice_txrx.c
@@ -18,6 +18,10 @@
 #define FDIR_DESC_RXDID 0x40
 #define ICE_FDIR_CLEAN_DELAY 10
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#include <ice_netmap_linux.h>
+#endif
+
 /**
  * ice_prgm_fdir_fltr - Program a Flow Director filter
  * @vsi: VSI to send dummy packet
@@ -208,6 +212,10 @@ static bool ice_clean_tx_irq(struct ice_ring *tx_ring, int napi_budget)
 	s16 i = tx_ring->next_to_clean;
 	struct ice_tx_desc *tx_desc;
 	struct ice_tx_buf *tx_buf;
+#ifdef DEV_NETMAP
+	if (tx_ring->netdev && netmap_tx_irq(tx_ring->netdev, tx_ring->q_index) != NM_IRQ_PASS)
+		return true;
+#endif /* DEV_NETMAP */
 
 	tx_buf = &tx_ring->tx_buf[i];
 	tx_desc = ICE_TX_DESC(tx_ring, i);
@@ -1067,6 +1075,16 @@ int ice_clean_rx_irq(struct ice_ring *rx_ring, int budget)
 	struct xdp_buff xdp;
 	bool failure;
 
+#ifdef DEV_NETMAP
+	if (rx_ring->netdev) {
+		int dummy, nm_irq;
+		nm_irq = netmap_rx_irq(rx_ring->netdev, rx_ring->q_index, &dummy);
+		if (nm_irq != NM_IRQ_PASS) {
+			return 1;
+		}
+	}
+#endif /* DEV_NETMAP */
+
 	/* Frame size depend on rx_ring setup when PAGE_SIZE=4K */
 #if (PAGE_SIZE < 8192)
 	frame_sz = ice_rx_frame_truesize(rx_ring, 0);
