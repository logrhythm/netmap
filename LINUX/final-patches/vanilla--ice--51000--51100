diff --git a/ice/ice_base.c b/ice/ice_base.c
index fafe020e46ee..a405f76a8824 100644
--- a/ice/ice_base.c
+++ b/ice/ice_base.c
@@ -5,6 +5,10 @@
 #include "ice_base.h"
 #include "ice_lib.h"
 #include "ice_dcb_lib.h"
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#define NETMAP_ICE_BASE
+#include <ice_netmap_linux.h>
+#endif
 
 static bool ice_alloc_rx_buf_zc(struct ice_rx_ring *rx_ring)
 {
@@ -446,6 +450,10 @@ static int ice_setup_rx_ctx(struct ice_rx_ring *ring)
 	/* Rx queue threshold in units of 64 */
 	rlan_ctx.lrxqthresh = 1;
 
+#ifdef DEV_NETMAP
+	ice_netmap_preconfigure_rx_ring(ring, &rlan_ctx);
+#endif /* DEV_NETMAP */
+
 	/* Enable Flexible Descriptors in the queue context which
 	 * allows this driver to select a specific receive descriptor format
 	 * increasing context priority to pick up profile ID; default is 0x01;
@@ -568,6 +576,11 @@ int ice_vsi_cfg_rxq(struct ice_rx_ring *ring)
 		return 0;
 	}
 
+#ifdef DEV_NETMAP
+	if (ice_netmap_configure_rx_ring(ring))
+		return 0;
+#endif /* DEV_NETMAP */
+
 	ice_alloc_rx_bufs(ring, num_bufs);
 
 	return 0;
@@ -834,6 +847,10 @@ ice_vsi_cfg_txq(struct ice_vsi *vsi, struct ice_tx_ring *ring,
 	if (pf_q == le16_to_cpu(txq->txq_id))
 		ring->txq_teid = le32_to_cpu(txq->q_teid);
 
+#ifdef DEV_NETMAP
+	ice_netmap_configure_tx_ring(ring);
+#endif /* DEV_NETMAP */
+
 	return 0;
 }
 
diff --git a/ice/ice_main.c b/ice/ice_main.c
index 73c61cdb036f..130eaaac16a1 100644
--- a/ice/ice_main.c
+++ b/ice/ice_main.c
@@ -47,6 +47,11 @@ static DEFINE_IDA(ice_aux_ida);
 DEFINE_STATIC_KEY_FALSE(ice_xdp_locking_key);
 EXPORT_SYMBOL(ice_xdp_locking_key);
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#define NETMAP_ICE_LIB
+#include <ice_netmap_linux.h>
+#endif
+
 static struct workqueue_struct *ice_wq;
 static const struct net_device_ops ice_netdev_safe_mode_ops;
 static const struct net_device_ops ice_netdev_ops;
@@ -4742,6 +4747,10 @@ ice_probe(struct pci_dev *pdev, const struct pci_device_id __always_unused *ent)
 	}
 
 	ice_devlink_register(pf);
+
+#ifdef DEV_NETMAP
+	ice_netmap_attach(pf);
+#endif
 	return 0;
 
 err_init_aux_unroll:
@@ -4841,6 +4850,10 @@ static void ice_remove(struct pci_dev *pdev)
 	struct ice_pf *pf = pci_get_drvdata(pdev);
 	int i;
 
+#ifdef DEV_NETMAP
+	ice_netmap_detach(pf);
+#endif /* DEV_NETMAP */
+
 	ice_devlink_unregister(pf);
 	for (i = 0; i < ICE_MAX_RESET_WAIT; i++) {
 		if (!ice_is_reset_in_progress(pf->state))
diff --git a/ice/ice_txrx.c b/ice/ice_txrx.c
index dccf09eefc75..c62ae39cf418 100644
--- a/ice/ice_txrx.c
+++ b/ice/ice_txrx.c
@@ -21,6 +21,10 @@
 #define FDIR_DESC_RXDID 0x40
 #define ICE_FDIR_CLEAN_DELAY 10
 
+#if defined(CONFIG_NETMAP) || defined(CONFIG_NETMAP_MODULE)
+#include <ice_netmap_linux.h>
+#endif
+
 /**
  * ice_prgm_fdir_fltr - Program a Flow Director filter
  * @vsi: VSI to send dummy packet
@@ -218,6 +222,10 @@ static bool ice_clean_tx_irq(struct ice_tx_ring *tx_ring, int napi_budget)
 	s16 i = tx_ring->next_to_clean;
 	struct ice_tx_desc *tx_desc;
 	struct ice_tx_buf *tx_buf;
+#ifdef DEV_NETMAP
+	if (tx_ring->netdev && netmap_tx_irq(tx_ring->netdev, tx_ring->q_index) != NM_IRQ_PASS)
+		return true;
+#endif /* DEV_NETMAP */
 
 	tx_buf = &tx_ring->tx_buf[i];
 	tx_desc = ICE_TX_DESC(tx_ring, i);
@@ -1104,6 +1112,16 @@ int ice_clean_rx_irq(struct ice_rx_ring *rx_ring, int budget)
 	struct xdp_buff xdp;
 	bool failure;
 
+#ifdef DEV_NETMAP
+	if (rx_ring->netdev) {
+		int dummy, nm_irq;
+		nm_irq = netmap_rx_irq(rx_ring->netdev, rx_ring->q_index, &dummy);
+		if (nm_irq != NM_IRQ_PASS) {
+			return 1;
+		}
+	}
+#endif /* DEV_NETMAP */
+
 	/* Frame size depend on rx_ring setup when PAGE_SIZE=4K */
 #if (PAGE_SIZE < 8192)
 	frame_sz = ice_rx_frame_truesize(rx_ring, 0);
